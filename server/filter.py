# Import necessary modules and classes
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain.agents.agent_toolkits import create_retriever_tool, create_conversational_retrieval_agent
from langchain_openai.chat_models import ChatOpenAI
import os

# Set the OpenAI API key for authentication
os.environ["OPENAI_API_KEY"] = "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"

# Load the document containing State of the Union addresses for the year 2023
loader = TextLoader('./State of the Union Address - 2023.txt')
documents = loader.load()

#debugging
# Load the document containing State of the Union addresses for the year 2023
file_path = './State of the Union Address - 2023.txt'
print("File path:", file_path)
loader = TextLoader(file_path)
documents = loader.load()
print("Documents:", documents)


# Split the document into smaller chunks to process more efficiently
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
texts = text_splitter.split_documents(documents)

# Use OpenAI default embeddings to convert text into numerical vectors
embeddings = OpenAIEmbeddings()

# Create a vector database using FAISS, a library for efficient similarity search and clustering of dense vectors
db = FAISS.from_documents(texts, embeddings)

# Create a retriever to interact with the vector database, allowing for document retrieval based on similarity
retriever = db.as_retriever()

# Create a tool for search functionality, which utilizes the retriever to search for documents
tool = create_retriever_tool(
    retriever,
    "search_state_of_union",
    "Searches and returns documents regarding the state-of-the-union."
)

# Wrap an LLM (OpenAI language model) with a conversational interface to make it suitable for dialogue
llm = ChatOpenAI(temperature=0)

# Create an agent executor that combines the language model with the retriever tool, enabling conversational retrieval
agent_executor = create_conversational_retrieval_agent(llm, [tool], verbose=True)

# Sample inputs to the conversational agent for testing
inputs = ["what is NATO?", "When was it created?"]

# Loop through the sample inputs and interact with the conversational agent
for input_text in inputs:
    # Invoke the agent with the input text to generate a response
    result = agent_executor.invoke({"input": input_text})

    # Print the response generated by the conversational agent
    print(result)
